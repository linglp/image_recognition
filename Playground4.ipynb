{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e6544026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for plotting\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "\n",
    "# keras imports for the dataset and building our neural network\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a2b5011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "10a77aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting some images\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(330 +i+1)\n",
    "    plt.tight_layout()\n",
    "    #ax.axis('off')\n",
    "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
    "    #plt.imshow(X_train[randint(0, X_train.shape[0])], cmap='gray', interpolation='none')\n",
    "    #plt.savefig('output/legend.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b9dcf",
   "metadata": {},
   "source": [
    "we could see that our dataset consists of small square 28 * 28 pixel grayscale of handwritten digits between 0 and 9. The training dataset has 60,000 squares while the testing dataset has 10,000 squares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "be2a124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb56bc",
   "metadata": {},
   "source": [
    "Note: Each image has 28 rows and 28 columns. \n",
    "One method is to convert the 2-D array to 1-D array by making one big input vector. But when we do so, we lose the spatial features, i.e., the arrangement of pixels in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b068ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_93 (Dense)            (None, 60)                47100     \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 10)                610       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 51,370\n",
      "Trainable params: 51,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# building the input vector from the 28x28 pixels\n",
    "trainX = X_train.reshape(60000, 784)\n",
    "testX = X_test.reshape(10000, 784)\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "\n",
    "\n",
    "# Normalize the data:\n",
    "trainX /= 255\n",
    "testX /= 255\n",
    "\n",
    "\n",
    "# we have 10 classes\n",
    "num_class = 10\n",
    "trainY = np_utils.to_categorical(y_train, num_class)\n",
    "testY = np_utils.to_categorical(y_test, num_class)\n",
    "\n",
    "n_cols = 784\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer \n",
    "input_layer = Dense(units = 60, activation='relu', input_shape= (n_cols,))\n",
    "model.add(input_layer) \n",
    "\n",
    "# # Add the second layer \n",
    "hidden_layer = Dense(units = 60, activation='sigmoid') \n",
    "model.add(hidden_layer)\n",
    "\n",
    "\n",
    "# # Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367df611",
   "metadata": {},
   "source": [
    "The total number of parameters in a given layer = number of nodes * number of features/n_cols + number of nodes. So for the first layer, the total number of parameters = 60 * 784 + 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5b14bdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 - 1s - loss: 0.6226 - accuracy: 0.8497 - 866ms/epoch - 2ms/step\n",
      "Epoch 2/5\n",
      "469/469 - 1s - loss: 0.2241 - accuracy: 0.9384 - 706ms/epoch - 2ms/step\n",
      "Epoch 3/5\n",
      "469/469 - 1s - loss: 0.1632 - accuracy: 0.9532 - 587ms/epoch - 1ms/step\n",
      "Epoch 4/5\n",
      "469/469 - 1s - loss: 0.1321 - accuracy: 0.9615 - 579ms/epoch - 1ms/step\n",
      "Epoch 5/5\n",
      "469/469 - 1s - loss: 0.1106 - accuracy: 0.9676 - 644ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY, epochs=5, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31d702",
   "metadata": {},
   "source": [
    "## Convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e5298774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# building the input vector from the 28x28 pixels\n",
    "trainX_n = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
    "testX_n = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
    "trainX_n = trainX_n.astype('float32')\n",
    "testX_n = testX_n.astype('float32')\n",
    "\n",
    "\n",
    "# Normalize the data:\n",
    "trainX_n /= 255\n",
    "testX_n /= 255\n",
    "\n",
    "print(trainX_n.shape)\n",
    "print(testX_n.shape)\n",
    "\n",
    "trainX_n = trainX_n.astype('float32')\n",
    "testX_n = testX_n.astype('float32')\n",
    "\n",
    "\n",
    "# we have 10 classes\n",
    "num_class = 10\n",
    "trainY_n = np_utils.to_categorical(y_train, num_class)\n",
    "testY_n = np_utils.to_categorical(y_test, num_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a4898",
   "metadata": {},
   "source": [
    "Note: our data is 28 * 28 pixel with no color. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ffc5e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 14, 14, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 60)                376380    \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 10)                610       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 377,310\n",
      "Trainable params: 377,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, kernel_size=(3,3), padding=\"same\", activation='relu', input_shape=(28, 28, 1))) # we first added a small filter (size 3*3) and also a small number of filters(32)\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(60, activation='relu'))\n",
    "cnn.add(Dense(10, activation='softmax')) # we have 10 digits to classify. (the total number of classes is 10)\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "cnn.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) # we use 'categorical-crossentropy' for multi-class classification\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cedd4589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(Conv)\n",
      " |  Conv2D(*args, **kwargs)\n",
      " |  \n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers or `None`, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`. You can use `None` when\n",
      " |  a dimension has variable size.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  >>> # The inputs are 28x28 RGB images with `channels_last` and the batch\n",
      " |  >>> # size is 4.\n",
      " |  >>> input_shape = (4, 28, 28, 3)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv2D(\n",
      " |  ... 2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 26, 26, 2)\n",
      " |  \n",
      " |  >>> # With `dilation_rate` as 2.\n",
      " |  >>> input_shape = (4, 28, 28, 3)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv2D(\n",
      " |  ... 2, 3, activation='relu', dilation_rate=2, input_shape=input_shape[1:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 24, 24, 2)\n",
      " |  \n",
      " |  >>> # With `padding` as \"same\".\n",
      " |  >>> input_shape = (4, 28, 28, 3)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv2D(\n",
      " |  ... 2, 3, activation='relu', padding=\"same\", input_shape=input_shape[1:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 28, 28, 2)\n",
      " |  \n",
      " |  >>> # With extended batch shape [4, 7]:\n",
      " |  >>> input_shape = (4, 7, 28, 28, 3)\n",
      " |  >>> x = tf.random.normal(input_shape)\n",
      " |  >>> y = tf.keras.layers.Conv2D(\n",
      " |  ... 2, 3, activation='relu', input_shape=input_shape[2:])(x)\n",
      " |  >>> print(y.shape)\n",
      " |  (4, 7, 26, 26, 2)\n",
      " |  \n",
      " |  \n",
      " |  Args:\n",
      " |    filters: Integer, the dimensionality of the output space (i.e. the number of\n",
      " |      output filters in the convolution).\n",
      " |    kernel_size: An integer or tuple/list of 2 integers, specifying the height\n",
      " |      and width of the 2D convolution window. Can be a single integer to specify\n",
      " |      the same value for all spatial dimensions.\n",
      " |    strides: An integer or tuple/list of 2 integers, specifying the strides of\n",
      " |      the convolution along the height and width. Can be a single integer to\n",
      " |      specify the same value for all spatial dimensions. Specifying any stride\n",
      " |      value != 1 is incompatible with specifying any `dilation_rate` value != 1.\n",
      " |    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |      `\"valid\"` means no padding. `\"same\"` results in padding with zeros evenly\n",
      " |      to the left/right or up/down of the input. When `padding=\"same\"` and\n",
      " |      `strides=1`, the output has the same size as the input.\n",
      " |    data_format: A string, one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs. `channels_last` corresponds\n",
      " |      to inputs with shape `(batch_size, height, width, channels)` while\n",
      " |      `channels_first` corresponds to inputs with shape `(batch_size, channels,\n",
      " |      height, width)`. It defaults to the `image_data_format` value found in\n",
      " |      your Keras config file at `~/.keras/keras.json`. If you never set it, then\n",
      " |      it will be `channels_last`.\n",
      " |    dilation_rate: an integer or tuple/list of 2 integers, specifying the\n",
      " |      dilation rate to use for dilated convolution. Can be a single integer to\n",
      " |      specify the same value for all spatial dimensions. Currently, specifying\n",
      " |      any `dilation_rate` value != 1 is incompatible with specifying any stride\n",
      " |      value != 1.\n",
      " |    groups: A positive integer specifying the number of groups in which the\n",
      " |      input is split along the channel axis. Each group is convolved separately\n",
      " |      with `filters / groups` filters. The output is the concatenation of all\n",
      " |      the `groups` results along the channel axis. Input channels and `filters`\n",
      " |      must both be divisible by `groups`.\n",
      " |    activation: Activation function to use. If you don't specify anything, no\n",
      " |      activation is applied (see `keras.activations`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix (see\n",
      " |      `keras.initializers`). Defaults to 'glorot_uniform'.\n",
      " |    bias_initializer: Initializer for the bias vector (see\n",
      " |      `keras.initializers`). Defaults to 'zeros'.\n",
      " |    kernel_regularizer: Regularizer function applied to the `kernel` weights\n",
      " |      matrix (see `keras.regularizers`).\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector (see\n",
      " |      `keras.regularizers`).\n",
      " |    activity_regularizer: Regularizer function applied to the output of the\n",
      " |      layer (its \"activation\") (see `keras.regularizers`).\n",
      " |    kernel_constraint: Constraint function applied to the kernel matrix (see\n",
      " |      `keras.constraints`).\n",
      " |    bias_constraint: Constraint function applied to the bias vector (see\n",
      " |      `keras.constraints`).\n",
      " |  \n",
      " |  Input shape:\n",
      " |    4+D tensor with shape: `batch_shape + (channels, rows, cols)` if\n",
      " |      `data_format='channels_first'`\n",
      " |    or 4+D tensor with shape: `batch_shape + (rows, cols, channels)` if\n",
      " |      `data_format='channels_last'`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    4+D tensor with shape: `batch_shape + (filters, new_rows, new_cols)` if\n",
      " |    `data_format='channels_first'` or 4+D tensor with shape: `batch_shape +\n",
      " |      (new_rows, new_cols, filters)` if `data_format='channels_last'`.  `rows`\n",
      " |      and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Returns:\n",
      " |    A tensor of rank 4+ representing\n",
      " |    `activation(conv2d(inputs, kernel) + bias)`.\n",
      " |  \n",
      " |  Raises:\n",
      " |    ValueError: if `padding` is `\"causal\"`.\n",
      " |    ValueError: when both `strides > 1` and `dilation_rate > 1`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      Conv\n",
      " |      keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      keras.utils.version_utils.LayerVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), groups=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Note here that `call()` method in `tf.keras` is little bit different\n",
      " |      from `keras` API. In `keras` API, you can pass support masking for\n",
      " |      layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n",
      " |      method to support masking.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
      " |          The first positional `inputs` argument is subject to special rules:\n",
      " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
      " |            arguments, and `inputs` cannot be provided via the default value\n",
      " |            of a keyword argument.\n",
      " |          - NumPy array or Python scalar values in `inputs` get cast as tensors.\n",
      " |          - Keras mask metadata is only collected from `inputs`.\n",
      " |          - Layers are built (`build(input_shape)` method)\n",
      " |            using shape info from `inputs` only.\n",
      " |          - `input_spec` compatibility is only checked against `inputs`.\n",
      " |          - Mixed precision input casting is only applied to `inputs`.\n",
      " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
      " |            casting behavior in mixed precision should be handled manually.\n",
      " |          - The SavedModel input specification is generated using `inputs` only.\n",
      " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
      " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
      " |            positional and keyword arguments.\n",
      " |        *args: Additional positional arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
      " |          this is not recommended, for the reasons above.\n",
      " |          The following optional keyword arguments are reserved:\n",
      " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
      " |            `mask` argument, its default value will be set to the mask generated\n",
      " |            for `inputs` by the previous layer (if `input` did come from a layer\n",
      " |            that generated a corresponding mask, i.e. if it came from a Keras\n",
      " |            layer with masking support).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  convolution_op(self, inputs, kernel)\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
      " |      every time it is called. The callers should make a copy of the returned dict\n",
      " |      if they want to modify it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: Positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |        - If the layer is not built, the method will call `build`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, **kwargs)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(self, inputs):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Activity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      d = tf.keras.layers.Dense(10)\n",
      " |      x = d(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |            inputs - Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_metric(self, value, name=None, **kwargs)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      This method can be used inside the `call()` method of a subclassed layer\n",
      " |      or model.\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
      " |        def __init__(self):\n",
      " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
      " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
      " |      \n",
      " |        def call(self, inputs):\n",
      " |          self.add_metric(self.mean(inputs))\n",
      " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any tensor passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      metrics become part of the model's topology and are tracked when you\n",
      " |      save the model via `save()`.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
      " |      Functional Model, as shown in the example below, is not supported. This is\n",
      " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        name: String metric name.\n",
      " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
      " |          Accepted values:\n",
      " |          `aggregation` - When the `value` tensor provided is not the result of\n",
      " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
      " |          using a `keras.Metric.Mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Args:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The variable created.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  finalize_state(self)\n",
      " |      Finalizes the layers state after updating layer weights.\n",
      " |      \n",
      " |      This function can be subclassed in a layer and will be called after updating\n",
      " |      a layer weights. It can be overridden to finalize any additional layer state\n",
      " |      after a weight update.\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first input node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first output node of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Args:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Deprecated, do NOT use!\n",
      " |      \n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer, as NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      returns both trainable and non-trainable weight values associated with this\n",
      " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
      " |      into similarly parameterized layers.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of NumPy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from NumPy arrays.\n",
      " |      \n",
      " |      The weights of a layer represent the state of the layer. This function\n",
      " |      sets the weight values from numpy arrays. The weight values should be\n",
      " |      passed in the order they are created by the layer. Note that the layer's\n",
      " |      weights must be instantiated before calling this function, by calling\n",
      " |      the layer.\n",
      " |      \n",
      " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
      " |      and the bias vector. These can be used to set the weights of another\n",
      " |      `Dense` layer:\n",
      " |      \n",
      " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
      " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
      " |      >>> layer_a.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
      " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
      " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[2.],\n",
      " |             [2.],\n",
      " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
      " |      >>> layer_b.get_weights()\n",
      " |      [array([[1.],\n",
      " |             [1.],\n",
      " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
      " |      \n",
      " |      Args:\n",
      " |        weights: a list of NumPy arrays. The number\n",
      " |          of arrays and their shape must match\n",
      " |          number of the dimensions of the weights\n",
      " |          of the layer (i.e. it should match the\n",
      " |          output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If the provided weights list does not match the\n",
      " |          layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Args:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  compute_dtype\n",
      " |      The dtype of the layer's computations.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
      " |      the weights.\n",
      " |      \n",
      " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
      " |      computations and the output to be in the compute dtype as well. This is done\n",
      " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
      " |      these casts if implementing your own layer.\n",
      " |      \n",
      " |      Layers often perform certain internal computations in higher precision when\n",
      " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
      " |      will still typically be float16 or bfloat16 in such cases.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The layer's compute dtype.\n",
      " |  \n",
      " |  dtype\n",
      " |      The dtype of the layer weights.\n",
      " |      \n",
      " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
      " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
      " |      dtype of the layer's computations.\n",
      " |  \n",
      " |  dtype_policy\n",
      " |      The dtype policy associated with this layer.\n",
      " |      \n",
      " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
      " |  \n",
      " |  dynamic\n",
      " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |      `InputSpec` instance(s) describing the input format for this layer.\n",
      " |      \n",
      " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
      " |      the layer to run input compatibility checks when it is called.\n",
      " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
      " |      of rank 4. As such, you can set, in `__init__()`:\n",
      " |      \n",
      " |      ```python\n",
      " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
      " |      ```\n",
      " |      \n",
      " |      Now, if you try to call the layer on an input that isn't rank 4\n",
      " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
      " |      error:\n",
      " |      \n",
      " |      ```\n",
      " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
      " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
      " |      ```\n",
      " |      \n",
      " |      Input checks that can be specified via `input_spec` include:\n",
      " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
      " |      - Shape\n",
      " |      - Rank (ndim)\n",
      " |      - Dtype\n",
      " |      \n",
      " |      For more information, see `tf.keras.layers.InputSpec`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
      " |  \n",
      " |  losses\n",
      " |      List of losses added using the `add_loss()` API.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
      " |      ...   def call(self, inputs):\n",
      " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
      " |      ...     return inputs\n",
      " |      >>> l = MyLayer()\n",
      " |      >>> l(np.ones((10, 1)))\n",
      " |      >>> l.losses\n",
      " |      [1.0]\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Activity regularization.\n",
      " |      >>> len(model.losses)\n",
      " |      0\n",
      " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      >>> len(model.losses)\n",
      " |      1\n",
      " |      \n",
      " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
      " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
      " |      >>> x = d(inputs)\n",
      " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      >>> model = tf.keras.Model(inputs, outputs)\n",
      " |      >>> # Weight regularization.\n",
      " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
      " |      >>> model.losses\n",
      " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |      List of metrics added using the `add_metric()` API.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
      " |      >>> d = tf.keras.layers.Dense(2)\n",
      " |      >>> output = d(input)\n",
      " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
      " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
      " |      >>> [m.name for m in d.metrics]\n",
      " |      ['max', 'min']\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of `Metric` objects.\n",
      " |  \n",
      " |  name\n",
      " |      Name of the layer (string), set in the constructor.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |      List of all non-trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Non-trainable weights are *not* updated during training. They are expected\n",
      " |      to be updated manually in `call()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of non-trainable variables.\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  supports_masking\n",
      " |      Whether this layer supports computing a mask using `compute_mask`.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |      List of all trainable weights tracked by this layer.\n",
      " |      \n",
      " |      Trainable weights are updated via gradient descent during training.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of trainable variables.\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variable_dtype\n",
      " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
      " |      themselves Keras layers.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      >>> class MyModule(tf.Module):\n",
      " |      ...   @tf.Module.with_name_scope\n",
      " |      ...   def __call__(self, x):\n",
      " |      ...     if not hasattr(self, 'w'):\n",
      " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
      " |      ...     return tf.matmul(x, self.w)\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      >>> mod = MyModule()\n",
      " |      >>> mod(tf.ones([1, 2]))\n",
      " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
      " |      >>> mod.w\n",
      " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
      " |      numpy=..., dtype=float32)>\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      >>> a = tf.Module()\n",
      " |      >>> b = tf.Module()\n",
      " |      >>> c = tf.Module()\n",
      " |      >>> a.b = b\n",
      " |      >>> b.c = c\n",
      " |      >>> list(a.submodules) == [b, c]\n",
      " |      True\n",
      " |      >>> list(b.submodules) == [c]\n",
      " |      True\n",
      " |      >>> list(c.submodules) == []\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "eecf42bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 - 18s - loss: 0.2488 - accuracy: 0.9228 - 18s/epoch - 10ms/step\n",
      "Epoch 2/5\n",
      "1875/1875 - 20s - loss: 0.0799 - accuracy: 0.9763 - 20s/epoch - 11ms/step\n",
      "Epoch 3/5\n",
      "1875/1875 - 19s - loss: 0.0517 - accuracy: 0.9842 - 19s/epoch - 10ms/step\n",
      "Epoch 4/5\n",
      "1875/1875 - 19s - loss: 0.0389 - accuracy: 0.9880 - 19s/epoch - 10ms/step\n",
      "Epoch 5/5\n",
      "1875/1875 - 20s - loss: 0.0293 - accuracy: 0.9909 - 20s/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "history_new = cnn.fit(trainX_n, trainY_n, epochs=5, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1737de54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
